```cuda
dim3(32, 64)
```

二维的编号, 后一项相同的是同一个worp(一定是32个线程), 和c相反

```cuda
dim3(64, 32)
```

后一项相同的分属两个worp

```cuda
dim3(4, 64)
```

0, 0 => 3, 7 是同一个worp

是先排成线性, 再截断

同一个worp中, 同一个线程最好跳着访问数据, worp之间访存是顺序的

cudaMemcpy粒度? 大概8m会达到峰值性能

block规模和硬件有关, 有上限, block个数和问题的规模有关

所有线程共享代码, spmd(单程序多数据, 但是流水线的个数和线程差不多),

simd(单指令多数据流, 共用流水线), mimd(每一个线程自己的代码), stmd(worp之间是spmd的, 不同worp之间执行代码的不同点, 同一个worp之内simd)

block之间需要同步, 但是worp之内天然同步的

block之内线程可以合作, shared mem几十k, barrier sync都在一个点上

不同block之间很难合作, 但是volatile可以啊, 加上的话汇编加上一个load

block太多的话, 就先放上去一些

一个核组可以运行多个block

cudaMalloc开到globalmemory上, 没有分页的, 上面没有os

修饰符: \__device__ 和 \__host__ 可以同时使用, 编译两次,

不能有函数指针, 没有本地变量, 参数不能变长

异步kernel调用? 调了kernel之后cpu还做事情

同步调用? 调完cpu等着

矩阵乘法, 优化

矩阵转置, 优化

解决流水线延迟? gpu是调用多个worp同时运行解决流水线延迟
