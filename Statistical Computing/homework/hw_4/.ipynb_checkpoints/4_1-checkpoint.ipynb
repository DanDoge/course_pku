{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import digamma as dga\n",
    "from scipy.special import gamma as ga\n",
    "from scipy.special import loggamma as lga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps=1e-10\n",
    "def log(x):\n",
    "    return np.log(x + eps)\n",
    "\n",
    "def digamma(x):\n",
    "    return dga(x + eps)\n",
    "\n",
    "def loggamma(x):\n",
    "    return lga(x + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(data):\n",
    "    vocab = np.array([i for i in range(100)])\n",
    "\n",
    "    num_doc = data.shape[0]\n",
    "    num_vocab = vocab.shape[0]\n",
    "    len_doc = data.shape[1]\n",
    "    num_topic = 10\n",
    "\n",
    "    w = np.zeros([num_doc, len_doc, num_vocab])\n",
    "    for d in range(num_doc):\n",
    "        for n in range(len_doc):\n",
    "            w[d, n, data[d, n]] = 1\n",
    "\n",
    "    alpha = np.ones(shape=num_topic)\n",
    "    eta = np.ones(shape=num_vocab)\n",
    "\n",
    "    phi = np.random.rand(num_doc, len_doc, num_topic)\n",
    "    for d in range(num_doc):\n",
    "        for n in range(len_doc):\n",
    "            phi[d, n] /= np.sum(phi[d, n])\n",
    "\n",
    "    gam = np.random.rand(num_doc, num_topic)\n",
    "    gam /= np.sum(gam, axis=1)[:, np.newaxis]\n",
    "\n",
    "    lam = np.random.rand(num_topic, num_vocab)\n",
    "    lam /= np.sum(lam, axis=1)[:, np.newaxis]\n",
    "    return lam, gam, phi, w, num_doc, num_topic, num_vocab, len_doc, alpha, eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step(lam, gam, phi, w, num_doc, num_topic, num_vocab, len_doc, alpha, eta):\n",
    "    #print(num_doc, num_topic, num_vocab)\n",
    "    for k in range(num_topic):\n",
    "        lam[k] = eta\n",
    "        for d in range(num_doc):\n",
    "            for n in range(len_doc):\n",
    "                lam[k] += phi[d, n, k] * w[d, n]\n",
    "    #lam /= np.sum(lam, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    gam = alpha + np.sum(phi, axis=1)\n",
    "    #gam /= np.sum(gam, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    def get_single_doc(lam, gam, phi, w, d):\n",
    "        for n in range(len_doc):\n",
    "            #phi[d, n, :] = np.exp(digamma(gam[d, :]) + digamma(lam[:, data[d, n]]) - digamma(np.sum(lam, axis=1)))\n",
    "            for k in range(num_topic):\n",
    "                phi[d, n, k] = np.exp(digamma(lam[k, data[d, n]]) - digamma(np.sum(lam[k])) + digamma(gam[d, k]) - digamma(np.sum(gam[d])))\n",
    "            phi[d, n, :] /= np.sum(phi[d, n, :])\n",
    "        return phi[d], d\n",
    "            \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        future_list = [executor.submit(get_single_doc, lam, gam, phi, w, d) for n in range(num_doc)]\n",
    "        for future in concurrent.futures.as_completed(future_list):\n",
    "            phi_d, d = future.result()\n",
    "            phi[d] = phi_d\n",
    "    \n",
    "    return lam, gam, phi, w, num_doc, num_topic, num_vocab, len_doc, alpha, eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def get_res1(lam, gam, phi, w):\n",
    "    res_1 = 0.0\n",
    "    res_1 += num_topic * loggamma(np.sum(eta))\n",
    "    res_1 -= num_topic * np.sum(loggamma(eta))\n",
    "    '''\n",
    "    for k in range(num_topic):\n",
    "        for i in range(num_vocab):\n",
    "            res_1 += (eta[i] - 1) * (digamma(lam[k, i]) - digamma(np.sum(lam[k])))\n",
    "    '''\n",
    "    return res_1\n",
    "\n",
    "\n",
    "def get_res2(lam, gam, phi, w):          \n",
    "    res_2 = 0.0\n",
    "    for n in range(len_doc):\n",
    "        for k in range(num_topic):\n",
    "            res_2 += phi[:, n, k] * (digamma(gam[:, k]) - digamma(np.sum(gam, axis=1)))\n",
    "    #res_2 -= digamma(np.sum(gam, axis=1))\n",
    "    res_2 = np.sum(res_2)\n",
    "    return res_2\n",
    "\n",
    "    \n",
    "def get_res3(lam, gam, phi, w):\n",
    "    res_3 = 0.0\n",
    "    res_3 += loggamma(np.sum(alpha))\n",
    "    res_3 -= np.sum(loggamma(alpha))\n",
    "    '''\n",
    "    for k in range(num_topic):\n",
    "        res_3 += (alpha[k] - 1) * (digamma(gam[:, k] - digamma(np.sum(gam[:, k]))))\n",
    "    '''\n",
    "    res_3 = np.sum(res_3)\n",
    "    return res_3\n",
    "\n",
    "def get_res4(lam, gam, phi, w):\n",
    "    res_4 = 0.0\n",
    "    def get_res4_single_loc(lam, gam, phi, w, n):\n",
    "        res_loc = 0.0\n",
    "        for k in range(num_topic):\n",
    "            sum_lam_k = np.sum(lam[k])\n",
    "            for i in range(num_vocab):\n",
    "                res_loc += phi[:, n, k] * w[:, n, i] * (digamma(lam[k, i]) - digamma(sum_lam_k))\n",
    "        res_loc = np.sum(res_loc)\n",
    "        return res_loc\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=32) as executor:\n",
    "        future_list = [executor.submit(get_res4_single_loc, lam, gam, phi, w, n) for n in range(len_doc)]\n",
    "        for future in concurrent.futures.as_completed(future_list):\n",
    "            res_4 += future.result()\n",
    "    return res_4\n",
    "\n",
    "def get_res5(lam, gam, phi, w):\n",
    "    res_5 = 0.0\n",
    "    for k in range(num_topic):\n",
    "        res_5 += loggamma(np.sum(lam[k])) - np.sum(loggamma(lam[k]))\n",
    "    for k in range(num_topic):\n",
    "        sum_lam_k = np.sum(lam[k])\n",
    "        #'''\n",
    "        res_5 += np.sum((lam[k] - 1) * (digamma(lam[k]) - digamma(sum_lam_k)))\n",
    "        '''\n",
    "        for i in range(num_vocab):\n",
    "            res_5 += (lam[k, i] - 1) * (digamma(lam[k, i]) - digamma(sum_lam_k))\n",
    "        '''\n",
    "    return -res_5\n",
    "    \n",
    "def get_res6(lam, gam, phi, w):\n",
    "    res_6 = 0.0\n",
    "    res_6 += np.sum(phi * log(phi))\n",
    "    return -res_6\n",
    "\n",
    "def get_res7(lam, gam, phi, w):\n",
    "    res_7 = 0.0\n",
    "    res_7 += loggamma(np.sum(gam, axis=1)) - np.sum(loggamma(gam), axis=1)\n",
    "    #print(res_7)\n",
    "    res_7 = np.sum(res_7)\n",
    "    for d in range(num_doc):\n",
    "        res_7 += np.sum((gam[d] - 1) * (digamma(gam[d]) - digamma(np.sum(gam[d]))))\n",
    "    return -res_7\n",
    "\n",
    "def elbo(lam, gam, phi, w):\n",
    "    res = 0.0\n",
    "    func_list = [get_res1, get_res2, get_res3, get_res4, get_res5, get_res6, get_res7]\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        future_list = [executor.submit(func, lam, gam, phi, w) for func in func_list]\n",
    "        for future in concurrent.futures.as_completed(future_list):\n",
    "            res += future.result()\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 done\n",
      "81.91079717323865\n"
     ]
    }
   ],
   "source": [
    "elbo_list = []\n",
    "for dsize in range(10, 100, 100):\n",
    "    data = np.load(\"mcs_hw4_p1_lda.npy\")[:dsize]\n",
    "    for i in range(1):\n",
    "        lam, gam, phi, w, num_doc, num_topic, num_vocab, len_doc, alpha, eta = init(data)\n",
    "        lam, gam, phi, w, num_doc, num_topic, num_vocab, len_doc, alpha, eta = one_step(lam, gam, phi, w, num_doc, num_topic, num_vocab, len_doc, alpha, eta)\n",
    "        print(\"iteration \" + str(i) + \" done\")\n",
    "        elbo_per_point = elbo(lam, gam, phi, w) / dsize\n",
    "        elbo_list.append(elbo_per_point)\n",
    "        print(elbo_per_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []\n",
    "r.append(get_res1(lam, gam, phi, w))\n",
    "r.append(get_res2(lam, gam, phi, w))\n",
    "r.append(get_res3(lam, gam, phi, w))\n",
    "r.append(get_res4(lam, gam, phi, w))\n",
    "r.append(get_res5(lam, gam, phi, w))\n",
    "r.append(get_res6(lam, gam, phi, w))\n",
    "r.append(get_res7(lam, gam, phi, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3591.3420536957537,\n",
       " 29975.665172861518,\n",
       " 12.801827480081469,\n",
       " -42892.826359328166,\n",
       " -4565.037847178694,\n",
       " 21169.832753067836,\n",
       " -1147.8711578569182]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"mcs_hw4_p1_lda.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 200)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
