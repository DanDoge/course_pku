{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import digamma as dga\n",
    "from scipy.special import gamma as ga\n",
    "from scipy.special import loggamma as lga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps=1e-10\n",
    "def log(x):\n",
    "    return np.log(x + eps)\n",
    "\n",
    "def digamma(x):\n",
    "    return dga(x + eps)\n",
    "\n",
    "def loggamma(x):\n",
    "    return lga(x + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(data):\n",
    "    vocab = np.array([i for i in range(100)])\n",
    "\n",
    "    num_doc = data.shape[0]\n",
    "    num_vocab = vocab.shape[0]\n",
    "    len_doc = data.shape[1]\n",
    "    num_topic = 10\n",
    "\n",
    "    w = np.zeros([num_doc, len_doc, num_vocab])\n",
    "    for d in range(num_doc):\n",
    "        for n in range(len_doc):\n",
    "            w[d, n, data[d, n]] = 1\n",
    "\n",
    "    alpha = np.ones(shape=num_topic)\n",
    "    eta = np.ones(shape=num_vocab)\n",
    "\n",
    "    phi = np.random.rand(num_doc, len_doc, num_topic)\n",
    "    for d in range(num_doc):\n",
    "        for n in range(len_doc):\n",
    "            phi[d, n] /= np.sum(phi[d, n])\n",
    "\n",
    "    gam = np.random.rand(num_doc, num_topic)\n",
    "    gam /= np.sum(gam, axis=1)[:, np.newaxis]\n",
    "\n",
    "    lam = np.random.rand(num_topic, num_vocab)\n",
    "    lam /= np.sum(lam, axis=1)[:, np.newaxis]\n",
    "    return lam, gam, phi, w, num_doc, num_topic, num_vocab, len_doc, alpha, eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_batch(lam, gam, phi, w, num_doc, num_topic, num_vocab, len_doc, alpha, eta, d_list):\n",
    "    #print(num_doc, num_topic, num_vocab)\n",
    "    for d in d_list:\n",
    "        gam[d] = alpha + np.sum(phi[d], axis=0)\n",
    "    #gam /= np.sum(gam, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    def get_single_doc(lam, gam, phi, w, d):\n",
    "        for n in range(len_doc):\n",
    "            #phi[d, n, :] = np.exp(digamma(gam[d, :]) + digamma(lam[:, data[d, n]]) - digamma(np.sum(lam, axis=1)))\n",
    "            for k in range(num_topic):\n",
    "                phi[d, n, k] = np.exp(digamma(lam[k, data[d, n]]) - digamma(np.sum(lam[k])) + digamma(gam[d, k]) - digamma(np.sum(gam[d])))\n",
    "            phi[d, n, :] /= np.sum(phi[d, n, :])\n",
    "        return phi[d], d\n",
    "            \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        future_list = [executor.submit(get_single_doc, lam, gam, phi, w, d) for d in d_list]\n",
    "        for future in concurrent.futures.as_completed(future_list):\n",
    "            phi_d, d = future.result()\n",
    "            phi[d] = phi_d\n",
    "            \n",
    "    lam_new = np.zeros_like(lam)\n",
    "    for k in range(num_topic):\n",
    "        lam[k] = eta\n",
    "        for n in range(len_doc):\n",
    "            for d in d_list:\n",
    "                lam_new[k] += phi[d, n, k] * w[d, n]\n",
    "    #lam /= np.sum(lam, axis=1)[:, np.newaxis]\n",
    "    lam_new *= num_doc / len(d_list)\n",
    "    lam = (1 - 0.1) * lam + 0.1 * lam_new\n",
    "    \n",
    "    return lam, gam, phi, w, num_doc, num_topic, num_vocab, len_doc, alpha, eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def get_res1(lam, gam, phi, w):\n",
    "    res_1 = 0.0\n",
    "    res_1 += num_topic * loggamma(np.sum(eta))\n",
    "    res_1 -= num_topic * np.sum(loggamma(eta))\n",
    "    '''\n",
    "    for k in range(num_topic):\n",
    "        for i in range(num_vocab):\n",
    "            res_1 += (eta[i] - 1) * (digamma(lam[k, i]) - digamma(np.sum(lam[k])))\n",
    "    '''\n",
    "    return res_1\n",
    "\n",
    "\n",
    "def get_res2(lam, gam, phi, w):          \n",
    "    res_2 = 0.0\n",
    "    for n in range(len_doc):\n",
    "        for k in range(num_topic):\n",
    "            res_2 += phi[:, n, k] * (digamma(gam[:, k]) - digamma(np.sum(gam, axis=1)))\n",
    "    #res_2 -= digamma(np.sum(gam, axis=1))\n",
    "    res_2 = np.sum(res_2)\n",
    "    return res_2\n",
    "\n",
    "    \n",
    "def get_res3(lam, gam, phi, w):\n",
    "    res_3 = 0.0\n",
    "    res_3 += loggamma(np.sum(alpha))\n",
    "    res_3 -= np.sum(loggamma(alpha))\n",
    "    '''\n",
    "    for k in range(num_topic):\n",
    "        res_3 += (alpha[k] - 1) * (digamma(gam[:, k] - digamma(np.sum(gam[:, k]))))\n",
    "    '''\n",
    "    res_3 = np.sum(res_3)\n",
    "    return res_3\n",
    "\n",
    "def get_res4(lam, gam, phi, w):\n",
    "    res_4 = 0.0\n",
    "    def get_res4_single_loc(lam, gam, phi, w, n):\n",
    "        res_loc = 0.0\n",
    "        for k in range(num_topic):\n",
    "            sum_lam_k = np.sum(lam[k])\n",
    "            for i in range(num_vocab):\n",
    "                res_loc += phi[:, n, k] * w[:, n, i] * (digamma(lam[k, i]) - digamma(sum_lam_k))\n",
    "        res_loc = np.sum(res_loc)\n",
    "        return res_loc\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=32) as executor:\n",
    "        future_list = [executor.submit(get_res4_single_loc, lam, gam, phi, w, n) for n in range(len_doc)]\n",
    "        for future in concurrent.futures.as_completed(future_list):\n",
    "            res_4 += future.result()\n",
    "    return res_4\n",
    "\n",
    "def get_res5(lam, gam, phi, w):\n",
    "    res_5 = 0.0\n",
    "    for k in range(num_topic):\n",
    "        res_5 += loggamma(np.sum(lam[k])) - np.sum(loggamma(lam[k]))\n",
    "    for k in range(num_topic):\n",
    "        sum_lam_k = np.sum(lam[k])\n",
    "        #'''\n",
    "        res_5 += np.sum((lam[k] - 1) * (digamma(lam[k]) - digamma(sum_lam_k)))\n",
    "        '''\n",
    "        for i in range(num_vocab):\n",
    "            res_5 += (lam[k, i] - 1) * (digamma(lam[k, i]) - digamma(sum_lam_k))\n",
    "        '''\n",
    "    return -res_5\n",
    "    \n",
    "def get_res6(lam, gam, phi, w):\n",
    "    res_6 = 0.0\n",
    "    res_6 += np.sum(phi * log(phi))\n",
    "    return -res_6\n",
    "\n",
    "def get_res7(lam, gam, phi, w):\n",
    "    res_7 = 0.0\n",
    "    res_7 += loggamma(np.sum(gam, axis=1)) - np.sum(loggamma(gam), axis=1)\n",
    "    #print(res_7)\n",
    "    res_7 = np.sum(res_7)\n",
    "    for d in range(num_doc):\n",
    "        res_7 += np.sum((gam[d] - 1) * (digamma(gam[d]) - digamma(np.sum(gam[d]))))\n",
    "    return -res_7\n",
    "\n",
    "def elbo(lam, gam, phi, w):\n",
    "    res = 0.0\n",
    "    func_list = [get_res1, get_res2, get_res3, get_res4, get_res5, get_res6, get_res7]\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        future_list = [executor.submit(func, lam, gam, phi, w) for func in func_list]\n",
    "        for future in concurrent.futures.as_completed(future_list):\n",
    "            res += future.result()\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13415850.69847013\n",
      "-13411352.604484007\n",
      "-13407381.119477594\n",
      "-13403744.100610454\n",
      "-13400350.856674936\n",
      "-13397148.80831987\n",
      "-13394103.68070577\n",
      "-13391191.378239358\n",
      "-13388394.046179956\n",
      "-13385697.931580737\n",
      "-13383092.121386476\n",
      "-13380567.749783404\n",
      "-13378117.475169478\n",
      "-13375735.121065846\n",
      "-13373415.421399714\n",
      "-13371153.834814157\n",
      "-13368946.406116113\n",
      "-13366789.660807159\n",
      "-13364680.523389403\n",
      "-13362616.253111832\n",
      "-13360594.39274647\n",
      "-13358612.727255605\n",
      "-13356669.250077972\n",
      "-13354762.135359233\n",
      "-13352889.714874763\n",
      "-13351050.458696967\n",
      "-13349242.958878573\n",
      "-13347465.91558851\n",
      "-13345718.125256885\n",
      "-13343998.47037969\n"
     ]
    }
   ],
   "source": [
    "def lda_batched(batch_size):\n",
    "    elbo_list = []\n",
    "    data = np.load(\"mcs_hw4_p1_lda.npy\")\n",
    "    lam, gam, phi, w, num_doc, num_topic, num_vocab, len_doc, alpha, eta = init(data)\n",
    "    for i in range(100):\n",
    "        for d in range(int(data.shape[0] / batch_size)):\n",
    "            d_list = [i for i in range(d, d + batch_size)]\n",
    "            lam, gam, phi, w, num_doc, num_topic, num_vocab, len_doc, alpha, eta = one_step_batch(lam, gam, phi, w, num_doc, num_topic, num_vocab, len_doc, alpha, eta, d_list)\n",
    "            #print(\"iteration \" + str(i) + \" done\")\n",
    "        elbo_per_point = elbo(lam, gam, phi, w)\n",
    "        elbo_list.append(elbo_per_point)\n",
    "        print(elbo_per_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"lda_elbo_batch\", \"wb\") as f:\n",
    "    pickle.dump(elbo_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
